[#tutorial]
= Tutorial

:idprefix: tutorial_

A `boost::bloom::filter` can be regarded as a bit array divided into _buckets_ that
are selected pseudo-randomly (based on a hash function) upon insertion:
each of the buckets is passed to a _subfilter_ that marks several of its bits according
to some associated strategy.

Note that although `boost::bloom::filter` mimics the interface of a container
and provides operations such as `insert`, it is actually _not_ a
container: for instance, insertion does not involve the actual storage
of the element in the data stucture, but merely sets some bits in the internal
array based on the hash value of the element.

== Filter Definition

[listing,subs="+macros,+quotes"]
-----
template<
  typename T, std::size_t K,
  typename Subfilter = block<unsigned char, 1>, std::size_t BucketSize = 0,
  typename Hash = boost::hash<T>, typename Allocator = std::allocator<T>  
>
class filter;
-----

* `T`: Type of the elements inserted.
* `K`: Number of buckets marked per insertion.
* `xref:tutorial_subfilter[Subfilter]`: Type of subfilter used.
* `xref:tutorial_bucketsize[BucketSize`]: Size in bytes of the buckets.
* `xref:tutorial_hash[Hash]`: A hash function for `T`.
* `Allocator`: An allocator for `T`.

=== `Subfilter`

The following subfilters can be selected, offering different compromises
between performance and _false positive rate_ (FPR).
See the xref:primer_variations_on_the_classical_filter[Bloom Filter Primer]
for a general explanation of block and multiblock filters.

`block<Block, K'>`

[.indent]
Sets `K'` bits in an underlying `Block` value. `Block` can be an
unsigned integral type  (e.g. `unsigned char`, `uint32_t`, `uint64_t`), or
an array of 2^`N`^ unsigned integrals (e.g. `uint64_t[8]`).
So, a `filter<T, K, block<Block, K'>>` will set `K * K'` bits per element.
The tradeoff here is that insertion/lookup will be (much) faster than
with `filter<T, K * K'>` while the FPR will be worse (larger).
FPR is better the wider `Block` is.

`multiblock<Block, K'>`

[.indent]
Instead of setting `K'` bits in a `Block` value, this subfilter sets
one bit on each of the elements of a `Block[K']` subarray. This improves FPR
but impacts performance with respect to `block<Block, K'>`, among other
things because cacheline boundaries can be crossed when accessing the subarray.

`fast_multiblock32<K'>`

[.indent]
Statistically equivalent to `multiblock<uint32_t, K'>`, but uses
faster SIMD-based algorithms when SSE2, AVX2 or Neon are enabled at
compile time.

`fast_multiblock64<K'>`

[.indent]
Statistically equivalent to `multiblock<uint64_t, K'>`, but uses a
faster SIMD-based algorithm when AVX2 is enabled at compile time.

The default configuration with `block<unsigned char,1>` corresponds to a
xref:primer[classical Bloom filter] setting `K` bits per element uniformly
distributed across the array.

=== `BucketSize`

When the default value 0 is used, buckets have the same size as
the _subarrays_ subfilters operate on (non-overlapping case).
Otherwise, bucket size is smaller and subarrays spill over adjacent buckets,
which results in an improved (lower) FPR in exchange for a possibly
worse performance due to memory unalignment.

image::bucket_size.png[align=center, title="Two different configurations of `BucketSize`: (a) non-overlapping subarrays, (b) overlapping subarrays.+++<br/>+++Each subarray is associated to the bucket of the same color."]

=== `Hash`

By default, link:../../../container_hash/index.html[Boost.ContainerHash] is used.
Consult this library's link:../../../container_hash/doc/html/hash.html#user[dedicated section]
if you need to extend `boost::hash` for your own types.

When the provided hash function is of sufficient quality, it is used
as is; otherwise, a bit-mixing post-process is applied to hash values that improves
their statistical properties so that the resulting FPR approaches its
theoretical limit. The hash function is determined to be of high quality
(more precisely, to have the so-called _avalanching_ property) via the
`link:../../../container_hash/doc/html/hash.html#ref_hash_is_avalanchinghash[boost::hash_is_avalanching]`
trait.

== Capacity

The size of the filter's internal array is specified at construction time:

[source,subs="+macros,+quotes"]
-----
using filter = boost::bloom::filter<std::string, 8>;
filter f(1'000'000); // array of 1'000'000 **bits**
std::cout << f.capacity(); // >= 1'000'000
-----

Note that `boost::bloom::filter` default constructor specifies a capacity
of zero, which in general won't be of much use -- the assigned array
is null.

Instead of specifying the array's capacity directly, we can let the library
figure it out based on the number of elements we plan to insert and the
desired FPR:

[source]
-----
// we'll insert 100'000 elements and want a FPR ~ 1%
filter f(100'000, 0.01);

// this is equivalent
filter f2(filter::capacity_for(100'000, 0.01));
-----

Be careful when the FPR specified is very small, as the resulting capacity
may be too large to fit in memory:

[source]
-----
// resulting capacity ~ 1.4E12, out of memory std::bad_alloc is thrown
filter f3(100'000, 1E-50);
-----

Once a filter is constructed, its array is fixed (for instance, it won't
grow dynamically as elements are inserted). The only way to change it is
by assignment/swapping from a different filter, or using `reset`:

[source,subs="+macros,+quotes"]
-----
f.reset(2'000'000); // change to 2'000'000 bits **and clears the filter**
f.reset(100'000, 0.005); // equivalent to reset(filter::capacity_for(100'000, 0.005));
f.reset(); // null array (capacity == 0)
-----

== Insertion and Lookup

Insertion is done in much the same way as with a traditional container:

[source]
-----
f.insert("hello");
f.emplace(100, 'X'); // ~ insert(std::string(100, 'X'))
f.insert(data.begin(), data.end());
-----

Of course, in this context "insertion" does not involve any actual
storage of elements into the filter, but rather the setting of bits in the
internal array based on the hash values of those elements.
Lookup goes as follows:

[source]
-----
bool b1 = f.may_contain("hello"); // b1 is true since we actually inserted "hello"
bool b2 = f.may_contain("bye"); // b2 is most likely false
-----

As its name suggests, `may_contain` can return `true` even if the
element has not been previously inserted, that is, it may yield false
positives -- this is the essence of probabilistic data structures.
`fpr_for` provides an estimation of the false positive rate:

[source]
-----
// we have inserted 100 elements so far, what's our FPR?
std::cout<< filter::fpr_for(100, f.capacity());
-----

Note that in the example we provided the number 100 externally:
`boost::bloom::filter` does not keep track of the number of elements
that have been inserted -- in other words, it does not have a `size`
operation.

Once inserted, there is no way to remove a specific element from the filter.
We can only clear up the filter entirely:

[source]
-----
f.clear(); // sets all the bits in the array to zero
-----

== Filter Combination

`boost::bloom::filter`+++s+++ can be combined by doing the OR logical operation
of the bits of their arrays:

[source]
-----
filter f2 = ...;
...
f |= f2; // f and f2 must have exactly the same capacity
-----

The result is equivalent to a filter "containing" the set union of the elements
of `f` and `f2`. AND combination, on the other hand, results in a filter
holding the _intersection_ of the elements:

[source]
-----
filter f3 = ...;
...
f &= f3; // f and f3 must have exactly the same capacity
-----

For AND combination, be aware that the resulting FPR will be in general
worse (higher) than if the filter had been constructed from scratch
by inserting only the commom elements -- don't trust `fpr_for` in this
case.

== Direct Access to the Array

The contents of the bit array can be accessed directly with the `array`
member function, which can be leveraged for filter serialization:

[source]
-----
filter f1 = ...;
...

// save filter
std::ofstream out("filter.bin", std::ios::binary);
std::size_t c1=f1.capacity();
out.write(reinterpret_cast<const char*>(&c1), sizeof(c1)); // save capacity (bits)
boost::span<const unsigned char> s1 = f1.array();
out.write(reinterpret_cast<const char*>(s1.data()), s1.size()); // save array
out.close();

// load filter
filter f2;
std::ifstream in("filter.bin", std::ios::binary);
std::size_t c2;
in.read(reinterpret_cast<char*>(&c2), sizeof(c2));
f2.reset(c2); // restore capacity
boost::span<unsigned char> s2 = f2.array();
in.read(reinterpret_cast<char*>(s2.data()), s2.size()); // load array
in.close();
-----

Note that `array()` is a span over `unsigned char`+++s+++ whereas
capacities are measured in bits, so `array.size()` is
`capacity() / CHAR_BIT`. If you load a serialized filter in a computer
other than the one where it was saved, take into account that
the CPU architectures at each end must have the same
https://es.wikipedia.org/wiki/Endianness[endianness^] for the
reconstruction to work.

== Debugging

=== Visual Studio Natvis

Add the link:../../extra/boost_bloom.natvis[`boost_bloom.natvis`^] visualizer
to your project to allow for user-friendly inspection of `boost::bloom::filter`+++s+++.

image::natvis.png[align=center, title="View of a `boost::bloom::filter` with `boost_bloom.natvis`."]

